{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "from collections import Counter\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATASET_DIR = \"BIGDATIOTPROJ/PlantVillage\"\n",
    "OUTPUT_DIR = \"BIGDATIOTPROJ/OutputDataset\"\n",
    "CLASS_BALANCE_TARGET = 2000  # Target number of samples per class\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "IMG_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "\n",
    "# Augmentation Pipeline\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to save augmented images\n",
    "def save_augmented_images(class_dir, images, target_count):\n",
    "    current_count = len(images)\n",
    "    print(f\"Balancing class: {class_dir} (current: {current_count}, target: {target_count})\")\n",
    "\n",
    "    for i in tqdm(range(current_count, target_count), desc=f\"Augmenting {class_dir}\"):\n",
    "        original_image = random.choice(images)\n",
    "        img = Image.open(original_image).convert(\"RGB\")\n",
    "        augmented_image = augmentation_transforms(img)\n",
    "        augmented_img_path = os.path.join(class_dir, f\"aug_{i}.jpg\")\n",
    "        transforms.ToPILImage()(augmented_image).save(augmented_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Balance the Dataset\n",
    "def balance_dataset(input_dir, output_dir, target_count):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    class_dirs = [d for d in os.listdir(input_dir) if os.path.isdir(os.path.join(input_dir, d))]\n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        output_class_path = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "\n",
    "        # Copy original images\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.lower().endswith(tuple(IMG_EXTENSIONS))]\n",
    "        for img_path in images:\n",
    "            shutil.copy(img_path, output_class_path)\n",
    "\n",
    "        # Perform augmentation if needed\n",
    "        save_augmented_images(output_class_path, images, target_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset_dir, output_dir, train_split, val_split, test_split):\n",
    "    # Allow a small tolerance for floating-point precision errors\n",
    "    assert abs(train_split + val_split + test_split - 1.0) < 1e-6, \"Splits must sum to 1.\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    class_dirs = [d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))]\n",
    "    for class_name in class_dirs:\n",
    "        class_path = os.path.join(dataset_dir, class_name)\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.lower().endswith(tuple(IMG_EXTENSIONS))]\n",
    "        random.shuffle(images)\n",
    "\n",
    "        train_count = int(len(images) * train_split)\n",
    "        val_count = int(len(images) * val_split)\n",
    "\n",
    "        train_images = images[:train_count]\n",
    "        val_images = images[train_count:train_count + val_count]\n",
    "        test_images = images[train_count + val_count:]\n",
    "\n",
    "        splits = {\"train\": train_images, \"val\": val_images, \"test\": test_images}\n",
    "        for split, split_images in splits.items():\n",
    "            split_dir = os.path.join(output_dir, split, class_name)\n",
    "            os.makedirs(split_dir, exist_ok=True)\n",
    "            for img_path in split_images:\n",
    "                shutil.copy(img_path, split_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balancing dataset...\")\n",
    "balance_dataset(DATASET_DIR, OUTPUT_DIR, CLASS_BALANCE_TARGET)\n",
    "\n",
    "print(\"Splitting dataset...\")\n",
    "split_dataset(OUTPUT_DIR, OUTPUT_DIR, TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT)\n",
    "\n",
    "print(\"Dataset prepared and saved to:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientnetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"BIGDATIOTPROJ/OutputDataset/Balanced_Split_Dataset\"  \n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 15\n",
    "dropout_p = 0.2\n",
    "in_f = 1280  \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names = [\"Pepper__bell___Bacterial_spot\", \"Pepper__bell___healthy\",\"Potato___Early_blight\", \"Potato___healthy\", \"Potato___Late_blight\", \"Tomato__Target_Spot\", \"Tomato__Tomato_mosaic_virus\", \"Tomato__Tomato_YellowLeaf__Curl_Virus\", \"Tomato_Bacterial_spot\", \"Tomato_Early_blight\", \"Tomato_healthy\", \"Tomato_Late_blight\", \"Tomato_Leaf_Mold\", \"Tomato_Septoria_leaf_spot\", \"Tomato_Spider_mites_Two_spotted_spider_mite\"]\n",
    "\n",
    "# Transforms for training and validation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"train\"), transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"val\"), transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(os.path.join(DATA_DIR, \"test\"), transform=val_test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "def create_effnet(num_classes):\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "    # Replace the classifier head\n",
    "    nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p, inplace=True),\n",
    "        nn.Linear(in_features=in_f, out_features=num_classes, bias=True))\n",
    "    return model\n",
    "\n",
    "# Training and validation loop\n",
    "def train_effnet(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience):\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += torch.sum(preds == labels)\n",
    "\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = train_correct.double() / len(train_loader.dataset)\n",
    "        train_loss_history.append(epoch_train_loss)\n",
    "        train_acc_history.append(epoch_train_acc.item())\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += torch.sum(preds == labels)\n",
    "\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_correct.double() / len(val_loader.dataset)\n",
    "        val_loss_history.append(epoch_val_loss)\n",
    "        val_acc_history.append(epoch_val_acc.item())\n",
    "\n",
    "        print(f\"Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f}\")\n",
    "        print(f\"Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            best_model_weights = model.state_dict()\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            print(\"Validation loss improved; saving model weights.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Stopping early due to no improvement for {patience} consecutive epochs.\")\n",
    "            break\n",
    "\n",
    "    # Load the best weights before returning\n",
    "    if best_model_weights:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "\n",
    "    return model, train_loss_history, val_loss_history, train_acc_history, val_acc_history\n",
    "\n",
    "# Test loop\n",
    "def test_effnet(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_acc = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return cm\n",
    "\n",
    "# Plot Training and Validation Metrics\n",
    "def plot_training_metrics(train_loss, val_loss, train_acc, val_acc, epochs):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Plot Training and Validation Loss\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(range(1, epochs + 1), train_loss, label=\"Training Loss\", color=\"blue\")\n",
    "    plt.plot(range(1, epochs + 1), val_loss, label=\"Validation Loss\", color=\"orange\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(range(1, epochs + 1), train_acc, label=\"Training Accuracy\", color=\"blue\")\n",
    "    plt.plot(range(1, epochs + 1), val_acc, label=\"Validation Accuracy\", color=\"orange\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patience\n",
    "PATIENCE = 3\n",
    "model = create_effnet(NUM_CLASSES)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train the model with early stopping\n",
    "print(\"Starting training...\")\n",
    "trained_model, train_loss_history, val_loss_history, train_acc_history, val_acc_history = train_effnet(\n",
    "    model, train_loader, val_loader, criterion, optimizer, EPOCHS, PATIENCE\n",
    ")\n",
    "\n",
    "# Plot Metrics\n",
    "epochs = len(train_loss_history)\n",
    "plot_training_metrics(train_loss_history, val_loss_history, train_acc_history, val_acc_history, epochs)\n",
    "\n",
    "# Test the model\n",
    "print(\"Starting testing...\")\n",
    "cm = test_effnet(trained_model, test_loader)\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_model.state_dict(), \"efficientnet_b0_early_stopping.pth\")\n",
    "print(\"Model saved as 'efficientnet_b0_early_stopping.pth'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolomodel = YOLO('yolo11n-cls.pt')\n",
    "\n",
    "results = yolomodel.train(data = DATA_DIR, epochs = 10, imgsz = 256, device = 'cpu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Configuration\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# Paths\n",
    "DATASET_DIR =   \"OutputDataset/Balanced_Split_Dataset\"\n",
    "MODEL_SAVE_PATH = \"BIGDATIOTPROJ\"\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "PATIENCE = 3\n",
    "\n",
    "# Data Transforms\n",
    "# Data Transforms\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize all images to 224x224\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Ensure validation images are also resized\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Ensure test images are also resized\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(DATASET_DIR, x), data_transforms[x])\n",
    "                  for x in [\"train\", \"val\", \"test\"]}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "               for x in [\"train\", \"val\", \"test\"]}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"val\", \"test\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "\n",
    "# Model Definition\n",
    "resmod = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "num_features = resmod.fc.in_features\n",
    "resmod.fc = nn.Sequential(\n",
    "        nn.Linear(in_features=2048, out_features=15, bias=True)\n",
    "    )\n",
    "resmod = resmod.to(DEVICE)\n",
    "\n",
    "# Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resmod.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Train Function with Early Stopping\n",
    "def train_resnet50(\n",
    "    model, dataloaders, criterion, optimizer, num_epochs, patience\n",
    "):\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_weights = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders[phase], desc=f\"{phase.capitalize()}\"):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            if phase == \"train\":\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_acc_history.append(epoch_acc.item())\n",
    "            else:\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc.item())\n",
    "\n",
    "                # Early Stopping\n",
    "                if epoch_loss < best_val_loss:\n",
    "                    best_val_loss = epoch_loss\n",
    "                    best_model_weights = model.state_dict()\n",
    "                    patience_counter = 0\n",
    "                    print(\"Validation loss improved; saving model weights.\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
    "\n",
    "        print(f\"Train Loss: {train_loss_history[-1]:.4f} Acc: {train_acc_history[-1]:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss_history[-1]:.4f} Acc: {val_acc_history[-1]:.4f}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Stopping early due to no improvement for {patience} consecutive epochs.\")\n",
    "            break\n",
    "\n",
    "    if best_model_weights:\n",
    "        model.load_state_dict(best_model_weights)\n",
    "\n",
    "    return model, train_loss_history, val_loss_history, train_acc_history, val_acc_history\n",
    "\n",
    "# Test Function\n",
    "def test_resnet(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            test_correct += torch.sum(preds == labels)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    test_acc = test_correct.double() / dataset_sizes[\"test\"]\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    return all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting ResNet-50 training with early stopping...\")\n",
    "trained_model, train_loss_history, val_loss_history, train_acc_history, val_acc_history = train_resnet50(\n",
    "    resmod, dataloaders, criterion, optimizer, EPOCHS, PATIENCE\n",
    ")\n",
    "\n",
    "print(\"Training completed. Plotting metrics...\")\n",
    "plot_training_metrics(train_loss_history, val_loss_history, train_acc_history, val_acc_history, len(train_loss_history))\n",
    "\n",
    "print(\"Testing the trained model...\")\n",
    "test_labels, test_preds = test_resnet(trained_model, dataloaders[\"test\"])\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "\n",
    "torch.save(trained_model.state_dict(), MODEL_SAVE_PATH)\n",
    "print(f\"Model saved to {MODEL_SAVE_PATH}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mobilenet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "DEVICE = \"cpu\"\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 3  # Early stopping patience\n",
    "\n",
    "# Data Transforms\n",
    "common_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Augmentation for train set\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load Datasets\n",
    "data_dir = \"C:/Users/Pratyush/Desktop/BIGDATIOTPROJ/OutputDataset/Balanced_Split_Dataset\"\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "datasets_dict = {}\n",
    "dataloaders_dict = {}\n",
    "\n",
    "# Check for each split and create datasets/dataloaders\n",
    "for split in splits:\n",
    "    split_path = os.path.join(data_dir, split)\n",
    "    if os.path.exists(split_path) and len(os.listdir(split_path)) > 0:\n",
    "        transform = train_transforms if split == \"train\" else common_transforms\n",
    "        datasets_dict[split] = datasets.ImageFolder(split_path, transform=transform)\n",
    "        dataloaders_dict[split] = DataLoader(datasets_dict[split], batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "        print(f\"{split.capitalize()} data loaded. Classes: {len(datasets_dict[split].classes)}\")\n",
    "    else:\n",
    "        print(f\"Warning: '{split}' directory missing or empty. Skipping...\")\n",
    "\n",
    "# Ensure at least train and val data are available\n",
    "if \"train\" not in datasets_dict or \"val\" not in datasets_dict:\n",
    "    raise ValueError(\"Both 'train' and 'val' datasets must be available!\")\n",
    "\n",
    "# Load Pretrained MobileNetV2\n",
    "mobilenet = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)\n",
    "mobilenet.classifier[1] = nn.Sequential(\n",
    "        nn.Dropout(p=0.2, inplace=False),\n",
    "        nn.Linear(in_features=1280, out_features=15, bias=True)\n",
    "    )\n",
    "mobilenet = mobilenet.to(DEVICE)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobilenet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training Loop\n",
    "train_loss_history, val_loss_history = [], []\n",
    "train_acc_history, val_acc_history = [], []\n",
    "\n",
    "print(\"Starting MobileNetV2 training...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase not in dataloaders_dict:\n",
    "            continue\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            mobilenet.train()\n",
    "        else:\n",
    "            mobilenet.eval()\n",
    "        \n",
    "        running_loss, running_corrects = 0.0, 0\n",
    "        \n",
    "        with tqdm(dataloaders_dict[phase], desc=f\"{phase.capitalize()} Phase\", leave=False) as tbar:\n",
    "            for inputs, labels in tbar:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = mobilenet(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                tbar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        epoch_loss = running_loss / len(datasets_dict[phase])\n",
    "        epoch_acc = running_corrects.double() / len(datasets_dict[phase])\n",
    "        \n",
    "        if phase == \"train\":\n",
    "            train_loss_history.append(epoch_loss)\n",
    "            train_acc_history.append(epoch_acc.item())\n",
    "        else:\n",
    "            val_loss_history.append(epoch_loss)\n",
    "            val_acc_history.append(epoch_acc.item())\n",
    "            \n",
    "            # Early stopping check\n",
    "            if epoch_loss < best_val_loss:\n",
    "                best_val_loss = epoch_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(mobilenet.state_dict(), \"best_mobilenet_model.pth\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "        \n",
    "        # Print metrics after each phase\n",
    "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "    \n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    remaining_time = epoch_duration * (EPOCHS - epoch - 1)\n",
    "    print(f\"Epoch Duration: {epoch_duration:.2f}s. Estimated Time Remaining: {remaining_time / 60:.2f} min.\")\n",
    "    \n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "mobilenet.load_state_dict(torch.load(\"best_mobilenet_model.pth\"))\n",
    "\n",
    "# Testing Phase\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "mobilenet.eval()\n",
    "test_corrects = 0\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(dataloaders_dict[\"test\"], desc=\"Testing\"):\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = mobilenet(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = test_corrects.double() / len(datasets_dict[\"test\"])\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=datasets_dict[\"test\"].classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data from the training log\n",
    "epochs = [1, 2, 3, 4, 5]\n",
    "train_loss = [0.2726, 0.1045, 0.0821, 0.0720, 0.0650]\n",
    "val_loss = [0.1329, 0.0465, 0.1012, 0.0558, 0.0812]\n",
    "train_acc = [0.9163, 0.9655, 0.9728, 0.9767, 0.9785]\n",
    "val_acc = [0.9558, 0.9845, 0.9700, 0.9808, 0.9762]\n",
    "\n",
    "# Plot Loss values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, label='Train Loss', marker='o')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=datasets_dict[\"test\"].classes)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Class names\n",
    "class_names = [\n",
    "    \"Pepper__bell___Bacterial_spot\", \"Pepper__bell___healthy\", \"Potato___Early_blight\", \n",
    "    \"Potato___healthy\", \"Potato___Late_blight\", \"Tomato__Target_Spot\", \n",
    "    \"Tomato__Tomato_mosaic_virus\", \"Tomato__Tomato_YellowLeaf__Curl_Virus\", \n",
    "    \"Tomato_Bacterial_spot\", \"Tomato_Early_blight\", \"Tomato_healthy\", \n",
    "    \"Tomato_Late_blight\", \"Tomato_Leaf_Mold\", \"Tomato_Septoria_leaf_spot\", \n",
    "    \"Tomato_Spider_mites_Two_spotted_spider_mite\"\n",
    "]\n",
    "\n",
    "# Confusion matrix data\n",
    "confusion_matrix = np.array([\n",
    "    [197, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 198, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 200, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 199, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 200, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 208, 0, 0, 0, 0, 0, 0, 6, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 188, 5, 1, 4, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 2, 191, 4, 2, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 199, 1, 0, 0, 0, 0, 0],\n",
    "    [4, 0, 2, 0, 0, 0, 3, 1, 0, 190, 0, 0, 0, 0, 0],\n",
    "    [4, 0, 2, 0, 0, 0, 3, 1, 0, 0, 199, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 5, 0, 0, 0, 4, 3, 188, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 321, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 199, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 199]\n",
    "])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(font_scale=0.8)  # Adjust for readability\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Rotate axis labels for better readability\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
