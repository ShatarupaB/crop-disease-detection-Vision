{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision matplotlib seaborn scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from PIL import Image, ImageEnhance\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"BIGDATIOTPROJ/PlantVillage\"\n",
    "output_directory = \"BIGDATIOTPROJ/PlantVillage/Output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loader to handle .JPG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(filename: str):\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'}\n",
    "    return filename.lower().endswith(tuple(valid_extensions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to apply image augmentation and enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(augment=False):\n",
    "    transform_list = [\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet-like normalization\n",
    "    ]\n",
    "    \n",
    "    if augment:\n",
    "        transform_list = [\n",
    "            transforms.RandomChoice([\n",
    "                transforms.RandomHorizontalFlip(p=1),\n",
    "                transforms.RandomVerticalFlip(p=1),\n",
    "                transforms.RandomApply([transforms.RandomRotation(15)], p=0.5),\n",
    "                transforms.Compose([transforms.RandomHorizontalFlip(p=1), transforms.RandomVerticalFlip(p=1)])\n",
    "            ]),\n",
    "            *transform_list\n",
    "        ]\n",
    "    \n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to balance the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_training_data(subset, target_size):\n",
    "    base_dataset = subset.dataset\n",
    "    class_indices = {label: [] for label in range(len(base_dataset.classes))}\n",
    "    for idx, subset_idx in enumerate(subset.indices):\n",
    "        _, label = base_dataset[subset_idx]\n",
    "        class_indices[label].append(subset_idx)\n",
    "    \n",
    "    augmented_indices = []\n",
    "    for label, indices in class_indices.items():\n",
    "        if len(indices) < target_size:\n",
    "            extra_count = target_size - len(indices)\n",
    "            augmented_indices.extend(indices)\n",
    "            augmented_indices.extend(random.choices(indices, k=extra_count))\n",
    "        else:\n",
    "            augmented_indices.extend(indices[:target_size])\n",
    "    \n",
    "    return Subset(base_dataset, augmented_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Function to create directories and move images to the corresponding folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_move_images(subset, base_dir, subset_name):\n",
    "    # Get the underlying dataset to access the classes\n",
    "    base_dataset = subset.dataset\n",
    "    \n",
    "    # Create directories for train, val, test with class subfolders\n",
    "    os.makedirs(os.path.join(base_dir, subset_name), exist_ok=True)\n",
    "    for class_name in base_dataset.classes:\n",
    "        os.makedirs(os.path.join(base_dir, subset_name, class_name), exist_ok=True)\n",
    "    \n",
    "    to_pil_image = transforms.ToPILImage()  # Convert tensor to PIL Image\n",
    "    \n",
    "    for idx in range(len(subset)):\n",
    "        img, label = subset[idx]\n",
    "        img_name = os.path.basename(subset.dataset.imgs[subset.indices[idx]][0])  # Get the image filename\n",
    "        class_folder = base_dataset.classes[label]\n",
    "        \n",
    "        # Convert the tensor to PIL Image and save it\n",
    "        pil_img = to_pil_image(img)\n",
    "        pil_img.save(os.path.join(base_dir, subset_name, class_folder, img_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split dataset and create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_and_create_folders(dataset_dir, train_size=0.7, val_size=0.15, test_size=0.15, balance_target_size=1500):\n",
    "    dataset = datasets.ImageFolder(root=dataset_dir, transform=get_transforms(augment=True), is_valid_file=is_valid_file)\n",
    "    total_size = len(dataset)\n",
    "    \n",
    "    train_len = int(train_size * total_size)\n",
    "    val_len = int(val_size * total_size)\n",
    "    test_len = total_size - train_len - val_len\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
    "    \n",
    "    # Augment and balance training data\n",
    "    balanced_train_dataset = augment_training_data(train_dataset, balance_target_size)\n",
    "    \n",
    "    # Apply preprocessing to validation and test sets\n",
    "    val_dataset.dataset.transform = get_transforms()\n",
    "    test_dataset.dataset.transform = get_transforms()\n",
    "\n",
    "    # Create directories and move images into appropriate folders\n",
    "    create_and_move_images(balanced_train_dataset, dataset_dir, 'train')\n",
    "    create_and_move_images(val_dataset, dataset_dir, 'val')\n",
    "    create_and_move_images(test_dataset, dataset_dir, 'test')\n",
    "\n",
    "    print(f\"Data has been split into {os.path.join(dataset_dir, 'train')}, {os.path.join(dataset_dir, 'val')}, {os.path.join(dataset_dir, 'test')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = \"C:/Users/Pratyush/Desktop/BIGDATIOTPROJ/PlantVillage\"\n",
    "    \n",
    "split_dataset_and_create_folders(dataset_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO11 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-cls.pt')\n",
    "\n",
    "results = model.train(data = dataset_directory, epochs = 10, imgsz = 256, device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split the dataset into train, val, and test if directories don't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_split_dataset(dataset_dir, split_ratios=(0.7, 0.15, 0.15)):\n",
    "    train_dir = os.path.join(dataset_dir, 'Train')\n",
    "    val_dir = os.path.join(dataset_dir, 'Val')\n",
    "    test_dir = os.path.join(dataset_dir, 'Test')\n",
    "\n",
    "    if not all([os.path.exists(train_dir), os.path.exists(val_dir), os.path.exists(test_dir)]):\n",
    "        print(\"Splitting dataset into Train, Val, and Test...\")\n",
    "\n",
    "        # Load the full dataset\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((227, 227)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)\n",
    "        total_len = len(dataset)\n",
    "\n",
    "        # Calculate sizes for train, val, and test splits\n",
    "        train_size = int(split_ratios[0] * total_len)\n",
    "        val_size = int(split_ratios[1] * total_len)\n",
    "        test_size = total_len - train_size - val_size\n",
    "\n",
    "        # Split the dataset\n",
    "        train_dataset, val_dataset, test_dataset = random_split(\n",
    "            dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "\n",
    "        # Create directories and move images into Train, Val, and Test folders\n",
    "        os.makedirs(train_dir, exist_ok=True)\n",
    "        os.makedirs(val_dir, exist_ok=True)\n",
    "        os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "        for subset, subset_dir in [(train_dataset, train_dir), (val_dataset, val_dir), (test_dataset, test_dir)]:\n",
    "            for img_path, label in [dataset.dataset.samples[idx] for idx in subset.indices]:\n",
    "                class_folder = dataset.classes[label]\n",
    "                target_folder = os.path.join(subset_dir, class_folder)\n",
    "                os.makedirs(target_folder, exist_ok=True)\n",
    "                img_name = os.path.basename(img_path)\n",
    "                os.rename(img_path, os.path.join(target_folder, img_name))\n",
    "        \n",
    "        print(\"Dataset split completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define transformations for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(augment=False):\n",
    "    transform_list = [\n",
    "        transforms.Resize((224, 224)),  # AlexNet requires 224x224 images\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet-like normalization\n",
    "    ]\n",
    "    \n",
    "    if augment:\n",
    "        transform_list = [\n",
    "            transforms.RandomChoice([\n",
    "                transforms.RandomHorizontalFlip(p=1),\n",
    "                transforms.RandomVerticalFlip(p=1),\n",
    "                transforms.RandomApply([transforms.RandomRotation(15)], p=0.5),\n",
    "                transforms.Compose([transforms.RandomHorizontalFlip(p=1), transforms.RandomVerticalFlip(p=1)])\n",
    "            ]),\n",
    "            *transform_list\n",
    "        ]\n",
    "    \n",
    "    return transforms.Compose(transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_dir, batch_size=32):\n",
    "    train_dataset = datasets.ImageFolder(root=f'{dataset_dir}/train', transform=get_transforms(augment=True))\n",
    "    val_dataset = datasets.ImageFolder(root=f'{dataset_dir}/val', transform=get_transforms())\n",
    "    test_dataset = datasets.ImageFolder(root=f'{dataset_dir}/test', transform=get_transforms())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
